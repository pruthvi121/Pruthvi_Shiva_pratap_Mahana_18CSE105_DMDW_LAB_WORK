{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DMDW_LAB_ASSIGNMENT_2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9SesBqAl82RFA+6+LVA0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pruthvi121/Pruthvi_Shiva_pratap_Mahana_18CSE105_DMDW_LAB_WORK/blob/main/DMDW_LAB_ASSIGNMENT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFgK_dLFvaO"
      },
      "source": [
        " **1.Downloading a dataset from kaggle and uploading it in jupyter notebook or google colab & Performing any random operation on the dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "OdIc7S24FYCC",
        "outputId": "2f49e147-b6c6-458e-cced-1c56a7556495"
      },
      "source": [
        "import pandas as pd\n",
        "url=\"https://raw.githubusercontent.com/Akash2oc98/18cse037-gietu_DMDW_lab-work/main/indian_food.csv\"\n",
        "df=pd.read_csv(url)\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>flavor_profile</th>\n",
              "      <th>course</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Balu shahi</td>\n",
              "      <td>Maida flour, yogurt, oil, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>45</td>\n",
              "      <td>25</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boondi</td>\n",
              "      <td>Gram flour, ghee, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>80</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gajar ka halwa</td>\n",
              "      <td>Carrots, milk, sugar, ghee, cashews, raisins</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Punjab</td>\n",
              "      <td>North</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ghevar</td>\n",
              "      <td>Flour, ghee, kewra, milk, clarified butter, su...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gulab jamun</td>\n",
              "      <td>Milk powder, plain flour, baking powder, ghee,...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>40</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>Til Pitha</td>\n",
              "      <td>Glutinous rice, black sesame seeds, gur</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Assam</td>\n",
              "      <td>North East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>Bebinca</td>\n",
              "      <td>Coconut milk, egg yolks, clarified butter, all...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>20</td>\n",
              "      <td>60</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Goa</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>Shufta</td>\n",
              "      <td>Cottage cheese, dry dates, dried rose petals, ...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Jammu &amp; Kashmir</td>\n",
              "      <td>North</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>Mawa Bati</td>\n",
              "      <td>Milk powder, dry fruits, arrowroot powder, all...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Madhya Pradesh</td>\n",
              "      <td>Central</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>Pinaca</td>\n",
              "      <td>Brown rice, fennel seeds, grated coconut, blac...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Goa</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>255 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               name  ...      region\n",
              "0        Balu shahi  ...        East\n",
              "1            Boondi  ...        West\n",
              "2    Gajar ka halwa  ...       North\n",
              "3            Ghevar  ...        West\n",
              "4       Gulab jamun  ...        East\n",
              "..              ...  ...         ...\n",
              "250       Til Pitha  ...  North East\n",
              "251         Bebinca  ...        West\n",
              "252          Shufta  ...       North\n",
              "253       Mawa Bati  ...     Central\n",
              "254          Pinaca  ...        West\n",
              "\n",
              "[255 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "81yJ6aJ1GDNX",
        "outputId": "73183525-80a5-4049-de47-6d829909b241"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>flavor_profile</th>\n",
              "      <th>course</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Balu shahi</td>\n",
              "      <td>Maida flour, yogurt, oil, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>45</td>\n",
              "      <td>25</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boondi</td>\n",
              "      <td>Gram flour, ghee, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>80</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gajar ka halwa</td>\n",
              "      <td>Carrots, milk, sugar, ghee, cashews, raisins</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Punjab</td>\n",
              "      <td>North</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ghevar</td>\n",
              "      <td>Flour, ghee, kewra, milk, clarified butter, su...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gulab jamun</td>\n",
              "      <td>Milk powder, plain flour, baking powder, ghee,...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>15</td>\n",
              "      <td>40</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             name  ... region\n",
              "0      Balu shahi  ...   East\n",
              "1          Boondi  ...   West\n",
              "2  Gajar ka halwa  ...  North\n",
              "3          Ghevar  ...   West\n",
              "4     Gulab jamun  ...   East\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "AM09mwqGGX8M",
        "outputId": "a662bbb0-8854-458a-9f7e-36e8856398a8"
      },
      "source": [
        "\n",
        "df.tail()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>flavor_profile</th>\n",
              "      <th>course</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>Til Pitha</td>\n",
              "      <td>Glutinous rice, black sesame seeds, gur</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Assam</td>\n",
              "      <td>North East</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>Bebinca</td>\n",
              "      <td>Coconut milk, egg yolks, clarified butter, all...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>20</td>\n",
              "      <td>60</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Goa</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>Shufta</td>\n",
              "      <td>Cottage cheese, dry dates, dried rose petals, ...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Jammu &amp; Kashmir</td>\n",
              "      <td>North</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>Mawa Bati</td>\n",
              "      <td>Milk powder, dry fruits, arrowroot powder, all...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Madhya Pradesh</td>\n",
              "      <td>Central</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>Pinaca</td>\n",
              "      <td>Brown rice, fennel seeds, grated coconut, blac...</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>Goa</td>\n",
              "      <td>West</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          name  ...      region\n",
              "250  Til Pitha  ...  North East\n",
              "251    Bebinca  ...        West\n",
              "252     Shufta  ...       North\n",
              "253  Mawa Bati  ...     Central\n",
              "254     Pinaca  ...        West\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wREX9as6Gi4L"
      },
      "source": [
        "**2.Practice 10 python programs using numpy libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N-eQfVkGe1U",
        "outputId": "094f3318-bb70-4c48-836c-895ced541930"
      },
      "source": [
        "#1.Write a NumPy program to create a 5x5 identity matrix, i.e. diagonal elements are 1, the rest are 0.\n",
        "import numpy as np\n",
        "x = np.eye(5,dtype=int)\n",
        "print(\"x =\\n\",x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =\n",
            " [[1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kxdf3eAG0_s",
        "outputId": "c38c9186-06f9-4406-ec35-015926748f35"
      },
      "source": [
        "\n",
        "#2.Write a NumPy program to convert a given array into a list and then convert it into a list again.\n",
        "import numpy as np\n",
        "a = [[1, 2], [3, 4]]\n",
        "x = np.array(a)\n",
        "print(\"list to array:\\n\",x)\n",
        "a2 = x.tolist()\n",
        "print(\"array to list:\\n\",a2)\n",
        "print(a == a2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list to array:\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "array to list:\n",
            " [[1, 2], [3, 4]]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUTh3YqUHKqK",
        "outputId": "150a522f-4135-468e-9311-e6476f1b177c"
      },
      "source": [
        "#3.Write a NumPy program to convert the Fahrenheit degree values into Centigrade degrees. Fahrenheit values are stored into a NumPy array.\n",
        "import numpy as np\n",
        "N=int(input())# not more than N inputs will be considered\n",
        "fvalues=list(map(float, input().split(' ')[:N]))\n",
        "F = np.array(fvalues)\n",
        "print(\"Values in Fahrenheit degrees:\")\n",
        "print(F)\n",
        "print(\"Values in  Centigrade degrees:\") \n",
        "print(5*F/9 - 5*32/9)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0 12 45.21 34 99.91  7 9 11\n",
            "Values in Fahrenheit degrees:\n",
            "[ 0.   12.   45.21 34.   99.91]\n",
            "Values in  Centigrade degrees:\n",
            "[-17.77777778 -11.11111111   7.33888889   1.11111111  37.72777778]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jbYm6HIHLsL",
        "outputId": "712cd5ef-9c58-4f42-f4c5-5e57537d9e28"
      },
      "source": [
        "#4.Write a NumPy program to compute the determinant of a given square array.\n",
        "import numpy as np\n",
        "from numpy import linalg as la  \n",
        "R = int(input(\"Enter the number of rows:\")) \n",
        "C = int(input(\"Enter the number of columns:\"))   \n",
        "\n",
        "if R==C:\n",
        "  print(\"Enter the entries in a single line (separated by space): \") \n",
        "  entries = list(map(int, input().split()))   \n",
        "  matrix = np.array(entries).reshape(R, C) \n",
        "  print(\"Original \",R,\"x\",C,\"-D matrix\")\n",
        "  print(matrix)\n",
        "  print(\"Determinant of the said \",R,\"x\",C,\"-D matrix\")\n",
        "  print(np.linalg.det(matrix))\n",
        "else:\n",
        "  print(\"Invalid Dimensional Array Input\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the number of rows:2\n",
            "Enter the number of columns:2\n",
            "Enter the entries in a single line (separated by space): \n",
            "1 0 1 2\n",
            "Original  2 x 2 -D matrix\n",
            "[[1 0]\n",
            " [1 2]]\n",
            "Determinant of the said  2 x 2 -D matrix\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3xOUmWaHbiE",
        "outputId": "db08ae76-5367-4308-abaf-f5e9bd5a5e7e"
      },
      "source": [
        "#5.Write a NumPy program to create a 5x5 array with random values and find the minimum and maximum values.\n",
        "import numpy as np\n",
        "x = np.random.random((5,5))\n",
        "print(\"Original Array:\")\n",
        "print(x) \n",
        "xmin, xmax = x.min(), x.max()\n",
        "print(\"Minimum and Maximum Values:\")\n",
        "print(xmin, xmax)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Array:\n",
            "[[0.32324799 0.07936319 0.82329441 0.95834318 0.55780086]\n",
            " [0.95113461 0.95741554 0.72653885 0.9271548  0.79614845]\n",
            " [0.20236538 0.83166876 0.93320956 0.68982094 0.88638094]\n",
            " [0.78757941 0.36802373 0.65094284 0.2833207  0.88665207]\n",
            " [0.1604581  0.97325472 0.6750452  0.53856011 0.46489278]]\n",
            "Minimum and Maximum Values:\n",
            "0.0793631891705685 0.9732547242549312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_lwJrogHlLE",
        "outputId": "4625500f-3e7d-4f6b-a895-3d4c73867a78"
      },
      "source": [
        "#6.Write a NumPy program to sort the specified number of elements from beginning of a given array.\n",
        "import numpy as np\n",
        "nums =  np.random.rand(15)\n",
        "print(\"Original array:\")\n",
        "print(nums)\n",
        "print(\"\\nSorted first 5 elements:\")\n",
        "print(nums[np.argpartition(nums,range(8))])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array:\n",
            "[0.54808844 0.67760039 0.86267787 0.41614791 0.90402338 0.31976575\n",
            " 0.63217959 0.98483009 0.27074821 0.72390022 0.28625213 0.30673455\n",
            " 0.21751516 0.83730165 0.92446592]\n",
            "\n",
            "Sorted first 5 elements:\n",
            "[0.21751516 0.27074821 0.28625213 0.30673455 0.31976575 0.41614791\n",
            " 0.54808844 0.63217959 0.67760039 0.72390022 0.86267787 0.90402338\n",
            " 0.98483009 0.83730165 0.92446592]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJgDO_kVHqNr",
        "outputId": "41d24c2f-8599-4849-af8d-697ef73dbbd5"
      },
      "source": [
        "#7.Write a NumPy program to calculate cumulative sum of the elements along a given axis, sum over rows for each of the 3 columns and sum over columns for each of the 2 rows of a given 3x3 array.\n",
        "import numpy as np\n",
        "x = np.array([[1,2,3], [4,5,6]])\n",
        "print(\"Original array: \")\n",
        "print(x)\n",
        "print(\"Cumulative sum of the elements along a given axis:\")\n",
        "r = np.cumsum(x)\n",
        "print(r)\n",
        "print(\"\\nSum over rows for each of the 3 columns:\")\n",
        "r = np.cumsum(x,axis=0) \n",
        "print(r)\n",
        "print(\"\\nSum over columns for each of the 2 rows:\")\n",
        "r = np.cumsum(x,axis=1) \n",
        "print(r)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array: \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Cumulative sum of the elements along a given axis:\n",
            "[ 1  3  6 10 15 21]\n",
            "\n",
            "Sum over rows for each of the 3 columns:\n",
            "[[1 2 3]\n",
            " [5 7 9]]\n",
            "\n",
            "Sum over columns for each of the 2 rows:\n",
            "[[ 1  3  6]\n",
            " [ 4  9 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqfvXgdwHubT",
        "outputId": "fc874296-c429-4e05-a94f-2432504b4b01"
      },
      "source": [
        "\n",
        "#8.Write a NumPy program to test element-wise of a given array for finiteness (not infinity or not Not a Number), positive or negative infinity, for NaN, for NaT (not a time), for negative infinity, for positive infinity.\n",
        "import numpy as np\n",
        "print(\"\\nTest element-wise for finiteness (not infinity or not Not a Number):\")\n",
        "print(np.isfinite(1))\n",
        "print(np.isfinite(0))\n",
        "print(np.isfinite(np.nan))\n",
        "print(\"\\nTest element-wise for positive or negative infinity:\")\n",
        "print(np.isinf(np.inf))\n",
        "print(np.isinf(np.nan))\n",
        "print(np.isinf(np.NINF))\n",
        "print(\"Test element-wise for NaN:\")\n",
        "print(np.isnan([np.log(-1.),1.,np.log(0)]))\n",
        "print(\"Test element-wise for NaT (not a time):\")\n",
        "print(np.isnat(np.array([\"NaT\", \"2016-01-01\"], dtype=\"datetime64[ns]\")))\n",
        "print(\"Test element-wise for negative infinity:\")\n",
        "x = np.array([-np.inf, 0., np.inf])\n",
        "y = np.array([2, 2, 2])\n",
        "print(np.isneginf(x, y))\n",
        "print(\"Test element-wise for positive infinity:\")\n",
        "x = np.array([-np.inf, 0., np.inf])\n",
        "y = np.array([2, 2, 2])\n",
        "print(np.isposinf(x, y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test element-wise for finiteness (not infinity or not Not a Number):\n",
            "True\n",
            "True\n",
            "False\n",
            "\n",
            "Test element-wise for positive or negative infinity:\n",
            "True\n",
            "False\n",
            "True\n",
            "Test element-wise for NaN:\n",
            "[ True False False]\n",
            "Test element-wise for NaT (not a time):\n",
            "[ True False]\n",
            "Test element-wise for negative infinity:\n",
            "[1 0 0]\n",
            "Test element-wise for positive infinity:\n",
            "[0 0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3C0AnbrHzqb",
        "outputId": "390d0d86-8ac6-4ca3-b88e-5a990e1cd49f"
      },
      "source": [
        "#9.Write a NumPy program to get the dates of yesterday, today and tomorrow.\n",
        "import numpy as np\n",
        "yesterday = np.datetime64('today', 'D') - np.timedelta64(1, 'D')\n",
        "print(\"Yestraday: \",yesterday)\n",
        "today     = np.datetime64('today', 'D')\n",
        "print(\"Today: \",today)\n",
        "tomorrow  = np.datetime64('today', 'D') + np.timedelta64(1, 'D')\n",
        "print(\"Tomorrow: \",tomorrow)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yestraday:  2020-11-22\n",
            "Today:  2020-11-23\n",
            "Tomorrow:  2020-11-24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG4dJrgxH4fE",
        "outputId": "48706895-f4dd-453f-8520-8b84de5d7a8c"
      },
      "source": [
        "#10.Write a NumPy program to remove the leading and trailing whitespaces of all the elements of a given array.\n",
        "import numpy as np\n",
        "x = np.array([' python exercises ', ' PHP  ', ' java  ', '  C++'], dtype=np.str)\n",
        "print(\"Original Array:\")\n",
        "print(x)\n",
        "stripped = np.char.strip(x)\n",
        "print(\"\\nRemove the leading and trailing whitespaces: \", stripped)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Array:\n",
            "[' python exercises ' ' PHP  ' ' java  ' '  C++']\n",
            "\n",
            "Remove the leading and trailing whitespaces:  ['python exercises' 'PHP' 'java' 'C++']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwfLM_ddH_Bb"
      },
      "source": [
        "**3.Practice 10 python programs using pandas libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQWuxViH7tl",
        "outputId": "86fa4708-ccc3-4d85-cea3-e8d60de70e1a"
      },
      "source": [
        "\n",
        "#1.Write a Pandas program to add, subtract, multiple and divide two Pandas Series.\n",
        "import pandas as pd\n",
        "ds1 = pd.Series([2, 4, 6, 8, 10])\n",
        "ds2 = pd.Series([1, 3, 5, 7, 9])\n",
        "ds = ds1 + ds2\n",
        "print(\"Add two Series:\")\n",
        "print(ds)\n",
        "print(\"Subtract two Series:\")\n",
        "ds = ds1 - ds2\n",
        "print(ds)\n",
        "print(\"Multiply two Series:\")\n",
        "ds = ds1 * ds2\n",
        "print(ds)\n",
        "print(\"Divide Series1 by Series2:\")\n",
        "ds = ds1 / ds2\n",
        "print(ds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Add two Series:\n",
            "0     3\n",
            "1     7\n",
            "2    11\n",
            "3    15\n",
            "4    19\n",
            "dtype: int64\n",
            "Subtract two Series:\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "dtype: int64\n",
            "Multiply two Series:\n",
            "0     2\n",
            "1    12\n",
            "2    30\n",
            "3    56\n",
            "4    90\n",
            "dtype: int64\n",
            "Divide Series1 by Series2:\n",
            "0    2.000000\n",
            "1    1.333333\n",
            "2    1.200000\n",
            "3    1.142857\n",
            "4    1.111111\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVand3_lIFks",
        "outputId": "ced7adcb-12fd-463b-bf3e-1c7d194b5805"
      },
      "source": [
        "\n",
        "#2.Write a Pandas program to iterate over rows in a DataFrame.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "exam_data = [{'name':'Anastasia', 'score':12.5}, {'name':'Dima','score':9}, {'name':'Katherine','score':16.5}]\n",
        "df = pd.DataFrame(exam_data)\n",
        "for index, row in df.iterrows():\n",
        "    print(row['name'], row['score'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anastasia 12.5\n",
            "Dima 9.0\n",
            "Katherine 16.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6vQ4saIIKM8",
        "outputId": "1e5207c6-3e31-42a2-ec12-b8020afdb1a7"
      },
      "source": [
        "#3.Write a Pandas program to start index with different value rather than 0 in a given DataFrame.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_of_birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'weight': [35, 37, 33, 30, 31, 32]})\n",
        "     \n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nDefault Index Range:\")\n",
        "print(df.index)\n",
        "df.index += 10 \n",
        "print(\"\\nNew Index Range:\")\n",
        "print(df.index)\n",
        "print(\"\\nDataFrame with new index:\")\n",
        "print(df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original DataFrame:\n",
            "  school_code class            name date_of_birth  weight\n",
            "0        s001     V  Alberto Franco    15/05/2002      35\n",
            "1        s002     V    Gino Mcneill    17/05/2002      37\n",
            "2        s003    VI     Ryan Parkes    16/02/1999      33\n",
            "3        s001    VI    Eesha Hinton    25/09/1998      30\n",
            "4        s002     V    Gino Mcneill    11/05/2002      31\n",
            "5        s004    VI    David Parkes    15/09/1997      32\n",
            "\n",
            "Default Index Range:\n",
            "RangeIndex(start=0, stop=6, step=1)\n",
            "\n",
            "New Index Range:\n",
            "RangeIndex(start=10, stop=16, step=1)\n",
            "\n",
            "DataFrame with new index:\n",
            "   school_code class            name date_of_birth  weight\n",
            "10        s001     V  Alberto Franco    15/05/2002      35\n",
            "11        s002     V    Gino Mcneill    17/05/2002      37\n",
            "12        s003    VI     Ryan Parkes    16/02/1999      33\n",
            "13        s001    VI    Eesha Hinton    25/09/1998      30\n",
            "14        s002     V    Gino Mcneill    11/05/2002      31\n",
            "15        s004    VI    David Parkes    15/09/1997      32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1KYRbw6IRv0",
        "outputId": "fba1fc06-db4d-40d6-b333-feae302d864a"
      },
      "source": [
        "#4.Write a Pandas program to extract only phone number from the specified column of a given DataFrame.\n",
        "import pandas as pd\n",
        "import re as re\n",
        "pd.set_option('display.max_columns', 10)\n",
        "df = pd.DataFrame({\n",
        "    'company_code': ['c0001','c0002','c0003', 'c0003', 'c0004'],\n",
        "    'company_phone_no': ['Company1-Phone no. 4695168357','Company2-Phone no. 8088729013','Company3-Phone no. 6204658086', 'Company4-Phone no. 5159530096', 'Company5-Phone no. 9037952371']\n",
        "    })\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "def find_phone_number(text):\n",
        "    ph_no = re.findall(r\"\\b\\d{10}\\b\",text)\n",
        "    return \"\".join(ph_no)\n",
        "df['number']=df['company_phone_no'].apply(lambda x: find_phone_number(x))\n",
        "print(\"\\Extracting numbers from dataframe columns:\")\n",
        "print(df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original DataFrame:\n",
            "  company_code               company_phone_no\n",
            "0        c0001  Company1-Phone no. 4695168357\n",
            "1        c0002  Company2-Phone no. 8088729013\n",
            "2        c0003  Company3-Phone no. 6204658086\n",
            "3        c0003  Company4-Phone no. 5159530096\n",
            "4        c0004  Company5-Phone no. 9037952371\n",
            "\\Extracting numbers from dataframe columns:\n",
            "  company_code               company_phone_no      number\n",
            "0        c0001  Company1-Phone no. 4695168357  4695168357\n",
            "1        c0002  Company2-Phone no. 8088729013  8088729013\n",
            "2        c0003  Company3-Phone no. 6204658086  6204658086\n",
            "3        c0003  Company4-Phone no. 5159530096  5159530096\n",
            "4        c0004  Company5-Phone no. 9037952371  9037952371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToWGdxJjIWa0",
        "outputId": "09d5288a-bc20-48ac-9ac6-a6b59ff65ec6"
      },
      "source": [
        "#5.Write a Pandas program to Combine two DataFrame objects by filling null values in one DataFrame with non-null values from other DataFrame.\n",
        "import pandas as pd\n",
        "df1 = pd.DataFrame({'A': [None, 0, None], 'B': [3, 4, 5]})\n",
        "df2 = pd.DataFrame({'A': [1, 1, 3], 'B': [3, None, 3]})\n",
        "df1.combine_first(df2)\n",
        "print(\"Original DataFrames:\")\n",
        "print(df1)\n",
        "print(\"--------------------\")\n",
        "print(df2)\n",
        "print(\"\\nMerge two dataframes with different columns:\")\n",
        "result = df1.combine_first(df2)\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original DataFrames:\n",
            "     A  B\n",
            "0  NaN  3\n",
            "1  0.0  4\n",
            "2  NaN  5\n",
            "--------------------\n",
            "   A    B\n",
            "0  1  3.0\n",
            "1  1  NaN\n",
            "2  3  3.0\n",
            "\n",
            "Merge two dataframes with different columns:\n",
            "     A  B\n",
            "0  1.0  3\n",
            "1  0.0  4\n",
            "2  3.0  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wowXIptUIaF0",
        "outputId": "3dfb2af1-affa-4651-825d-df5e1a43c1bf"
      },
      "source": [
        "\n",
        "#6.Write a Pandas program to create\n",
        "#a) Datetime object for Jan 15 2012.\n",
        "#b) Specific date and time of 9:20 pm.\n",
        "#c) Local date and time.\n",
        "#d) A date without time.\n",
        "#e) Current date.\n",
        "#f) Time from a datetime.\n",
        "#g) Current local time.\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "print(\"Datetime object for Jan 11 2012:\")\n",
        "print(datetime(2012, 1, 11))\n",
        "print(\"\\nSpecific date and time of 9:20 pm\") \n",
        "print(datetime(2011, 1, 11, 21, 20))\n",
        "print(\"\\nLocal date and time:\")\n",
        "print(datetime.now())\n",
        "print(\"\\nA date without time: \")\n",
        "print(datetime.date(datetime(2012, 5, 22)))\n",
        "print(\"\\nCurrent date:\")\n",
        "print(datetime.now().date())\n",
        "print(\"\\nTime from a datetime:\")\n",
        "print(datetime.time(datetime(2012, 12, 15, 18, 12)))\n",
        "print(\"\\nCurrent local time:\") \n",
        "print(datetime.now().time())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datetime object for Jan 11 2012:\n",
            "2012-01-11 00:00:00\n",
            "\n",
            "Specific date and time of 9:20 pm\n",
            "2011-01-11 21:20:00\n",
            "\n",
            "Local date and time:\n",
            "2020-11-23 03:24:41.314619\n",
            "\n",
            "A date without time: \n",
            "2012-05-22\n",
            "\n",
            "Current date:\n",
            "2020-11-23\n",
            "\n",
            "Time from a datetime:\n",
            "18:12:00\n",
            "\n",
            "Current local time:\n",
            "03:24:41.315090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT2FCAtXIdXs",
        "outputId": "51d1e8b3-088a-45ed-ef85-9def2d071c1c"
      },
      "source": [
        "\n",
        "#7.Write a Pandas program to find out the alcohol consumption details in the year '1986' or '1989' where WHO region is 'Americas' or 'Europe' from the world alcohol consumption dataset.\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/Akash2oc98/18cse037-gietu_DMDW_lab-work/main/world_alcohol.csv\"\n",
        "w_a_con =pd.read_csv(url)\n",
        "print(\"World alcohol consumption sample data:\")\n",
        "print(w_a_con.head())\n",
        "print(\"\\nThe world alcohol consumption details in the year ‘1986’ or ‘1989’ where  WHO region is ‘Americas’  or 'Europe':\")\n",
        "print(w_a_con[((w_a_con['Year']==1985) | (w_a_con['Year']==1989)) & ((w_a_con['WHO region']=='Americas') | (w_a_con['WHO region']=='Europe'))].head(10))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "World alcohol consumption sample data:\n",
            "   Year       WHO region                Country Beverage Types  Display Value\n",
            "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
            "1  1986         Americas                Uruguay          Other           0.50\n",
            "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
            "3  1986         Americas               Colombia           Beer           4.27\n",
            "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
            "\n",
            "The world alcohol consumption details in the year ‘1986’ or ‘1989’ where  WHO region is ‘Americas’  or 'Europe':\n",
            "    Year WHO region                                            Country  \\\n",
            "11  1989   Americas                                          Guatemala   \n",
            "21  1989   Americas                                         Costa Rica   \n",
            "26  1985     Europe  United Kingdom of Great Britain and Northern I...   \n",
            "35  1985   Americas                              Saint Kitts and Nevis   \n",
            "44  1985     Europe                                          Lithuania   \n",
            "50  1985     Europe                                        Switzerland   \n",
            "55  1989   Americas                                           Suriname   \n",
            "57  1989     Europe                                            Croatia   \n",
            "64  1989   Americas                   Bolivia (Plurinational State of)   \n",
            "78  1989   Americas                                            Jamaica   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "11           Beer           0.62  \n",
            "21        Spirits           4.51  \n",
            "26           Wine           1.36  \n",
            "35        Spirits           2.24  \n",
            "44          Other            NaN  \n",
            "50          Other           0.30  \n",
            "55           Wine           0.04  \n",
            "57           Wine           5.10  \n",
            "64           Beer           1.26  \n",
            "78          Other           0.00  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93VNKV32Ihjj",
        "outputId": "d72623b6-f740-4bb9-c6d9-10e1c6e14ee0"
      },
      "source": [
        "#8\n",
        "\"\"\"Write a Pandas program to split the following dataset using group by on 'salesman_id' and find the first order date for each group.\n",
        "\n",
        "Test Data:\n",
        "\n",
        "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
        "0    70001     150.50  2012-10-05         3002         5002\n",
        "1    70009     270.65  2012-09-10         3001         5003\n",
        "2    70002      65.26  2012-10-05         3001         5001\n",
        "3    70004     110.50  2012-08-17         3003         5003\n",
        "4    70007     948.50  2012-09-10         3002         5002\n",
        "5    70005    2400.60  2012-07-27         3002         5001\n",
        "6    70008    5760.00  2012-09-10         3001         5001\n",
        "7    70010    1983.43  2012-10-10         3004         5003\n",
        "8    70003    2480.40  2012-10-10         3003         5003\n",
        "9    70012     250.45  2012-06-27         3002         5002\n",
        "10   70011      75.29  2012-08-17         3003         5003\n",
        "11   70013    3045.60  2012-04-25         3001         5001\"\"\"\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5004,5003,5002,5004,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroupby to find first order date for each group(salesman_id):\")\n",
        "result = df.groupby('salesman_id')['ord_date'].min()\n",
        "print(result)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Orders DataFrame:\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0    70001     150.50  2012-10-05         3005         5002\n",
            "1    70009     270.65  2012-09-10         3001         5005\n",
            "2    70002      65.26  2012-10-05         3002         5001\n",
            "3    70004     110.50  2012-08-17         3009         5003\n",
            "4    70007     948.50  2012-09-10         3005         5002\n",
            "5    70005    2400.60  2012-07-27         3007         5001\n",
            "6    70008    5760.00  2012-09-10         3002         5001\n",
            "7    70010    1983.43  2012-10-10         3004         5004\n",
            "8    70003    2480.40  2012-10-10         3009         5003\n",
            "9    70012     250.45  2012-06-27         3008         5002\n",
            "10   70011      75.29  2012-08-17         3003         5004\n",
            "11   70013    3045.60  2012-04-25         3002         5001\n",
            "\n",
            "Groupby to find first order date for each group(salesman_id):\n",
            "salesman_id\n",
            "5001    2012-04-25\n",
            "5002    2012-06-27\n",
            "5003    2012-08-17\n",
            "5004    2012-08-17\n",
            "5005    2012-09-10\n",
            "Name: ord_date, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg4rrOnnIsgD",
        "outputId": "264aa20e-0eec-4a76-95f3-c2fccde25771"
      },
      "source": [
        "#9\n",
        "\"\"\"Write a Pandas program to find and replace the missing values in a given DataFrame which do not have any valuable information.\n",
        "\n",
        "Example:\n",
        "Missing values: ?, --\n",
        "Replace those values with NaN\n",
        "\n",
        "Test Data:\n",
        "\n",
        "   ord_no purch_amt    ord_date customer_id salesman_id\n",
        "0   70001     150.5           ?        3002        5002\n",
        "1     NaN    270.65  2012-09-10        3001        5003\n",
        "2   70002     65.26         NaN        3001           ?\n",
        "3   70004     110.5  2012-08-17        3003        5001\n",
        "4     NaN     948.5  2012-09-10        3002         NaN\n",
        "5   70005    2400.6  2012-07-27        3001        5002\n",
        "6      --      5760  2012-09-10        3001        5001\n",
        "7   70010         ?  2012-10-10        3004           ?\n",
        "8   70003     12.43  2012-10-10          --        5003\n",
        "9   70012    2480.4  2012-06-27        3002        5002\n",
        "10    NaN    250.45  2012-08-17        3001        5003\n",
        "11  70013    3045.6  2012-04-25        3001          --   \"\"\"\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,\"--\",70010,70003,70012,np.nan,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,\"?\",12.43,2480.4,250.45, 3045.6],\n",
        "'ord_date': ['?','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,\"--\",3002,3001,3001],\n",
        "'salesman_id':[5002,5003,\"?\",5001,np.nan,5002,5001,\"?\",5003,5002,5003,\"--\"]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nReplace the missing values with NaN:\")\n",
        "result = df.replace({\"?\": np.nan, \"--\": np.nan})\n",
        "print(result)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Orders DataFrame:\n",
            "   ord_no purch_amt    ord_date customer_id salesman_id\n",
            "0   70001     150.5           ?        3002        5002\n",
            "1     NaN    270.65  2012-09-10        3001        5003\n",
            "2   70002     65.26         NaN        3001           ?\n",
            "3   70004     110.5  2012-08-17        3003        5001\n",
            "4     NaN     948.5  2012-09-10        3002         NaN\n",
            "5   70005    2400.6  2012-07-27        3001        5002\n",
            "6      --      5760  2012-09-10        3001        5001\n",
            "7   70010         ?  2012-10-10        3004           ?\n",
            "8   70003     12.43  2012-10-10          --        5003\n",
            "9   70012    2480.4  2012-06-27        3002        5002\n",
            "10    NaN    250.45  2012-08-17        3001        5003\n",
            "11  70013    3045.6  2012-04-25        3001          --\n",
            "\n",
            "Replace the missing values with NaN:\n",
            "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0   70001.0     150.50         NaN       3002.0       5002.0\n",
            "1       NaN     270.65  2012-09-10       3001.0       5003.0\n",
            "2   70002.0      65.26         NaN       3001.0          NaN\n",
            "3   70004.0     110.50  2012-08-17       3003.0       5001.0\n",
            "4       NaN     948.50  2012-09-10       3002.0          NaN\n",
            "5   70005.0    2400.60  2012-07-27       3001.0       5002.0\n",
            "6       NaN    5760.00  2012-09-10       3001.0       5001.0\n",
            "7   70010.0        NaN  2012-10-10       3004.0          NaN\n",
            "8   70003.0      12.43  2012-10-10          NaN       5003.0\n",
            "9   70012.0    2480.40  2012-06-27       3002.0       5002.0\n",
            "10      NaN     250.45  2012-08-17       3001.0       5003.0\n",
            "11  70013.0    3045.60  2012-04-25       3001.0          NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "1U_1a0tkI14j",
        "outputId": "a60338aa-1fc3-4cb3-ef26-84a52804ae4a"
      },
      "source": [
        "\n",
        "#10.Create a dataframe of ten rows, four columns with random values. Write a Pandas program to display bar charts in dataframe on specified columns.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(24)\n",
        "df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n",
        "df = pd.concat([df, pd.DataFrame(np.random.randn(10, 4), columns=list('BCDE'))],\n",
        "               axis=1)\n",
        "df.iloc[0, 2] = np.nan\n",
        "df.iloc[3, 3] = np.nan\n",
        "df.iloc[4, 1] = np.nan\n",
        "df.iloc[9, 4] = np.nan\n",
        "print(\"Original array:\")\n",
        "print(df)\n",
        "print(\"\\nBar charts in dataframe:\")\n",
        "df.style.bar(subset=['B', 'C'], color='#d65f5f')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original array:\n",
            "      A         B         C         D         E\n",
            "0   1.0  1.329212       NaN -0.316280 -0.990810\n",
            "1   2.0 -1.070816 -1.438713  0.564417  0.295722\n",
            "2   3.0 -1.626404  0.219565  0.678805  1.889273\n",
            "3   4.0  0.961538  0.104011       NaN  0.850229\n",
            "4   5.0       NaN  1.057737  0.165562  0.515018\n",
            "5   6.0 -1.336936  0.562861  1.392855 -0.063328\n",
            "6   7.0  0.121668  1.207603 -0.002040  1.627796\n",
            "7   8.0  0.354493  1.037528 -0.385684  0.519818\n",
            "8   9.0  1.686583 -1.325963  1.428984 -2.089354\n",
            "9  10.0 -0.129820  0.631523 -0.586538       NaN\n",
            "\n",
            "Bar charts in dataframe:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 89.2%, transparent 89.2%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 16.8%, transparent 16.8%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col2,#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 62.7%, transparent 62.7%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 78.1%, transparent 78.1%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 58.3%, transparent 58.3%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 94.3%, transparent 94.3%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 8.7%, transparent 8.7%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 75.6%, transparent 75.6%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 52.8%, transparent 52.8%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col2,#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 59.8%, transparent 59.8%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 93.6%, transparent 93.6%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 4.3%, transparent 4.3%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col1{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 45.2%, transparent 45.2%);\n",
              "        }#T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col2{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 78.2%, transparent 78.2%);\n",
              "        }</style><table id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >A</th>        <th class=\"col_heading level0 col1\" >B</th>        <th class=\"col_heading level0 col2\" >C</th>        <th class=\"col_heading level0 col3\" >D</th>        <th class=\"col_heading level0 col4\" >E</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col1\" class=\"data row0 col1\" >1.329212</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col2\" class=\"data row0 col2\" >nan</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col3\" class=\"data row0 col3\" >-0.316280</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row0_col4\" class=\"data row0 col4\" >-0.990810</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col0\" class=\"data row1 col0\" >2.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col1\" class=\"data row1 col1\" >-1.070816</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col2\" class=\"data row1 col2\" >-1.438713</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.564417</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.295722</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col0\" class=\"data row2 col0\" >3.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col1\" class=\"data row2 col1\" >-1.626404</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0.219565</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0.678805</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row2_col4\" class=\"data row2 col4\" >1.889273</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col0\" class=\"data row3 col0\" >4.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.961538</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.104011</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col3\" class=\"data row3 col3\" >nan</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0.850229</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col0\" class=\"data row4 col0\" >5.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col1\" class=\"data row4 col1\" >nan</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col2\" class=\"data row4 col2\" >1.057737</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0.165562</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row4_col4\" class=\"data row4 col4\" >0.515018</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col0\" class=\"data row5 col0\" >6.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col1\" class=\"data row5 col1\" >-1.336936</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0.562861</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col3\" class=\"data row5 col3\" >1.392855</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row5_col4\" class=\"data row5 col4\" >-0.063328</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col0\" class=\"data row6 col0\" >7.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.121668</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col2\" class=\"data row6 col2\" >1.207603</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col3\" class=\"data row6 col3\" >-0.002040</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row6_col4\" class=\"data row6 col4\" >1.627796</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col0\" class=\"data row7 col0\" >8.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0.354493</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col2\" class=\"data row7 col2\" >1.037528</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col3\" class=\"data row7 col3\" >-0.385684</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row7_col4\" class=\"data row7 col4\" >0.519818</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col0\" class=\"data row8 col0\" >9.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col1\" class=\"data row8 col1\" >1.686583</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col2\" class=\"data row8 col2\" >-1.325963</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col3\" class=\"data row8 col3\" >1.428984</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row8_col4\" class=\"data row8 col4\" >-2.089354</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col0\" class=\"data row9 col0\" >10.000000</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col1\" class=\"data row9 col1\" >-0.129820</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col2\" class=\"data row9 col2\" >0.631523</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col3\" class=\"data row9 col3\" >-0.586538</td>\n",
              "                        <td id=\"T_b2faa958_2d3b_11eb_b96d_0242ac1c0002row9_col4\" class=\"data row9 col4\" >nan</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f42ab533a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_9201oYI6M0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}